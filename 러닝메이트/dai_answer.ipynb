{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\r2com\\anaconda3\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: fancyimpute in c:\\users\\r2com\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: knnimpute>=0.1.0 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (1.5.2)\n",
      "Requirement already satisfied: cvxpy in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (1.6.0)\n",
      "Requirement already satisfied: cvxopt in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: pytest in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (7.4.4)\n",
      "Requirement already satisfied: nose in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\n",
      "Requirement already satisfied: osqp>=0.6.2 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from cvxpy->fancyimpute) (0.6.7.post3)\n",
      "Requirement already satisfied: clarabel>=0.5.0 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from cvxpy->fancyimpute) (0.9.0)\n",
      "Requirement already satisfied: scs>=3.2.4.post1 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from cvxpy->fancyimpute) (3.2.7)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from pytest->fancyimpute) (0.4.6)\n",
      "Requirement already satisfied: qdldl in c:\\users\\r2com\\anaconda3\\lib\\site-packages (from osqp>=0.6.2->cvxpy->fancyimpute) (0.1.7.post4)\n"
     ]
    }
   ],
   "source": [
    "##제일먼저 설치해주세요\n",
    "\n",
    "!pip install xgboost \n",
    "!pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##사용 라이브러리\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from fancyimpute import IterativeImputer\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 고정\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed=42\n",
    "seed_everything(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터\n",
    "path = '@@@@@'\n",
    "\n",
    "train_csv = @@@(path + 'train.csv')\n",
    "test_csv = @@@(path + 'test.csv')\n",
    "submit_csv = @@@(path + 'sample_submission.csv')\n",
    "\n",
    "#.데이터 제대로 붙은지 확인하기\n",
    "# print(train_csv)\n",
    "# print(test_csv)\n",
    "# print(submit_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#찾아보기!#\n",
    "#iterativeImputer (결측치 처리 방법중 하나)\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "train_csv['배터리용량'] = imputer.fit_transform(train_csv[['배터리용량']])\n",
    "test_csv['배터리용량'] = imputer.transform(test_csv[['배터리용량']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련할 변수\n",
    "x = @@@\n",
    "y = @@@\n",
    "\n",
    "#테스트 파일\n",
    "x_test1 = @@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### @@필요라이브러리 import \n",
    "\n",
    "#라벨인코딩\n",
    "categorical_features = [col for col in x.columns if x[col].dtype == 'object']\n",
    "\n",
    "# LabelEncoder 적용\n",
    "for col in categorical_features:\n",
    "    le = @@@\n",
    "    x[col] = le.fit_transform(x[col])\n",
    "    x_test1[col] = le.transform(x_test1[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치처리\n",
    "\n",
    "# def fit_outlier(data):  \n",
    "#     data = @@.DataFrame(data) #데이터를 dataframe 형식으로 변환\n",
    "#     for label in data:\n",
    "#         series = data[label]\n",
    "#         q1 = series.quantile(0.25)      \n",
    "#         q3 = series.quantile(0.75)\n",
    "#         iqr = q3 - q1\n",
    "#         upper_bound = q3 + iqr\n",
    "#         lower_bound = q1 - iqr\n",
    "        \n",
    "#         series[series > upper_bound] = np.nan\n",
    "#         series[series < lower_bound] = np.nan\n",
    "#         print(#@@결측치 확인@@)\n",
    "#         series = series.interpolate()\n",
    "#         data[label] = data[label].interpolate() \n",
    "        \n",
    "#     data = data.fillna(data.@@@)\n",
    "#     return data\n",
    "\n",
    "# #이상치처리한 데이터로 바꾸기\n",
    "# x = @@@@@\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 스케일링\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# x_scaled = @@@\n",
    "# x_test1 = @@@@\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###교차검증###\n",
    "\n",
    "# KFold 설정\n",
    "n_splits = @@\n",
    "kfold = KFold(n_splits=@@, shuffle=@@, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##파라미터 설정\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 7000, \n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.022967280267686598, \n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.01585944217292061,\n",
    "    'subsample': 0.9583496415625028, \n",
    "    'colsample_bytree': 0.9124943873276311,\n",
    "    'lambda': 9.133524592946834, \n",
    "    'alpha': 2.379891161256474}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "r2_scores =  @@\n",
    "rmse_scores = @@\n",
    "models = @@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      "Fold 1 R2 Score: 0.9986, RMSE: 1.3929\n",
      "Fold 1 Training Time: 3.21 seconds\n",
      "\n",
      "--- Fold 2 ---\n",
      "Fold 2 R2 Score: 0.9987, RMSE: 1.3382\n",
      "Fold 2 Training Time: 3.57 seconds\n",
      "\n",
      "--- Fold 3 ---\n",
      "Fold 3 R2 Score: 0.9984, RMSE: 1.4482\n",
      "Fold 3 Training Time: 3.11 seconds\n",
      "\n",
      "--- Fold 4 ---\n",
      "Fold 4 R2 Score: 0.9987, RMSE: 1.3633\n",
      "Fold 4 Training Time: 3.81 seconds\n",
      "\n",
      "--- Fold 5 ---\n",
      "Fold 5 R2 Score: 0.9986, RMSE: 1.3823\n",
      "Fold 5 Training Time: 3.95 seconds\n",
      "\n",
      "--- Fold 6 ---\n",
      "Fold 6 R2 Score: 0.9992, RMSE: 1.0344\n",
      "Fold 6 Training Time: 3.34 seconds\n",
      "\n",
      "--- Fold 7 ---\n",
      "Fold 7 R2 Score: 0.9984, RMSE: 1.3815\n",
      "Fold 7 Training Time: 3.96 seconds\n"
     ]
    }
   ],
   "source": [
    "# KFold 교차 검증\n",
    "for fold, (train_index, val_index) in enumerate(kfold.split(x_scaled)):\n",
    "    print(f\"\\n--- Fold {fold + 1} ---\")\n",
    "    \n",
    "    # 훈련 및 검증 데이터 분리\n",
    "    x_train_fold, x_val_fold = x_scaled[train_index], x_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "    \n",
    "    # 모델 생성\n",
    "    model = XGBRegressor(@@)\n",
    "    \n",
    "    \n",
    "    # 모델 학습\n",
    "    start_time = time.time()\n",
    "    model.fit(\n",
    "        x_train_fold, y_train_fold,\n",
    "        eval_set=[(x_val_fold, y_val_fold)],  \n",
    "        \n",
    "        verbose=False\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # 예측 및 평가\n",
    "    y_val_pred = model.predict(@@@)\n",
    "    r2 = r2_score(@@@)\n",
    "    rmse = np.sqrt(mean_squared_error(@@@))\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    rmse_scores.append(rmse)\n",
    "    models.append(model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} R2 Score: {r2:.4f}, RMSE: {rmse:.4f}\")\n",
    "    print(f\"Fold {fold + 1} Training Time: {round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 모델로 전체 데이터 학습\n",
    "final_model = XGBRegressor(**best_params)\n",
    "final_model.fit(\n",
    "    @@@, @@,\n",
    "    eval_set=[(x_val_fold, y_val_fold)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_submit = final_model.predict(@@@)\n",
    "\n",
    "# 결과 저장\n",
    "@@@@ = y_submit\n",
    "# print(submit_csv)\n",
    "\n",
    "ltm = time.localtime(time.time())\n",
    "save_time = f\"{ltm.tm_year}{ltm.tm_mon}{ltm.tm_mday}{ltm.tm_hour}{ltm.tm_min}{ltm.tm_sec}\"\n",
    "\n",
    "\n",
    "submit_csv.to_csv(path + f\"submission_{save_time}_rmse_{np.mean(rmse_scores):.4f}.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
